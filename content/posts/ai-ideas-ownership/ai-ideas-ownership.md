+++
title = 'Which Ideas Are Mine?: Thinking About AI Generated Content'
date = 2025-01-03T15:57:46-05:00
draft = true
+++

People are using AI systems, like ChatGPT, to generate content. You can create articles, digital art, ideas, websites, letters and so much more by just asking an AI model to do it for you. With the increasing amount of AI generated or assisted content, there needs to be a discussion around what it means to own this type of content. Which AI generated content can I say is mine?

### Some Thought Experiments On Ownership

There are a lot of intuitions we already have about ownership of AI content. Here are some examples to probe them.

> ### Writing a Love Letter to a Spouse:
>
> Valentine's Day is coming next week and Peter wants to write his spouse a beauitful letter to let them know how he feels about them. Peter goes to ChatGPT and prompts:

> "Write my wife Taylor a beautiful letter for Valentine's Day. Tell her how much I love her and our two kids Dax and Scott. Mention our first date in London and how I still love her as much as I do now 12 years later."

> Peter, copies, pastes, then prints out the AI generated output and gives it to his wife without mentioning how he made it. She loves it and says its one of the most thoughtful things she's ever read.

Is what Peter did wrong?

Most people will read this scenario and say that what Peter did was wrong. The main factor is that peter was deceptive. By giving the letter to his wife and not mentioning it was AI generated he lied by omission. A lie which if Taylor knew the truth of may upset her.

Here is another thought experiment to consider:

> ### Writing a Love Letter to a Spouse 2:

> Valentine's Day is coming next week and Peter wants to write his spouse a beauitful letter to let them know how he feels about them. He wants to use ChatGPT to help him. He has already written the full letter, pastes it into ChatGPT and asks for it to fix any grammatical or spelling errors. He takes the output, copies, pastes, then prints it out and gives it to his wife without mentioning how he made it. She loves it and says its one of the most thoughtful things she's ever read.

Is what Peter did wrong?

Most people in this scenario would likely say what Peter did is not wrong. It feels like although the AI tool assisted him, it didn't do the entire thing. Most of the work he shared remained untouched and writing tools to fix these types of things are widely accepted already.

Here we have two cases where someone uses ChatGPT and shares the output as their own work. In one case we can clearly denounce the action as wrong, while in the other feel completely okay with it.

> ### Creating Music with AI:
>
> Sara wants to create some music. She goes to an AI music generating website suno.com. On suno she makes a free account, logs in, then prompts the AI application with:

> A bossa nova song about a falling in love with gingerbread man cookie.

> Sara takes the song then posts it on her Instagram saying she created the song.

Is what Sara did wrong?

Again most people would say this is clearly wrong. Sara put it little to no effort and now is claiming she created the song, misleading her followers. Some might push back and say that the core idea of a Bossa Nova Gingerbread man song gives her some right to claim it it hers, but I do not find that convincing.

> ### Creating Music with AI 2:

> Sara is working on creating some music, but is having a hard time getting started. She goes to ChatGPT and types in the following prompt:

> Can you give me an interesting chord progression in the Bossa Nova style in the key of Bb?

> Sara reviews the suggested progressions, then selects one of them. She uses the progression for the verse, records herself playing the chords. She then writes her own melody and sings over the chords.

> Sara takes the song then posts it to Instagram saying she created the song.

Is what Sara did wrong?

This is our hardest case yet. While Sara used AI for inspiration, she still created most of the song. Chord progressions are important to the music, but are often shared and reused across artists, especially in genres like Bossa Nova. Additionally, she didn't just blindly take the chord progression, she looked at a few and with her own taste selected the one she wanted.
In this case I personally do not think Sara is wrong, but this is importantly different from the second letter writing case. In this situation Sara did take meaningful content, in the letter writing it was purely just editing what was already there.

### Effort Varies Morality of Claims

After visiting the 4 scenarios, it seems clear that we have strong intuitions about the morality of these cases. What theory can we develop to explain why we have these different reactions? We saw earlier that the amount of effort put into the work is one explanation.

> Scenario 1:
> Peter quickly shares some facts and a basic prompt. Copies the entire generated letter.

> Scenario 2:
> Peter writes an entire letter. AI application proofreads and makes syntatic edits.

> Scenario 3:
> Sara gives a one-sentence prompt to the app. Shares the generated song.

> Scenario 4:
> Sara uses a model to generate some chord progressions for inspiration. Picks one she likes, performs the chords, writes a melody, sings and produces the song.

Scenarios 1 and 3 are instances where the human puts minimal effort in. In Scenario 2 and 4, the human effort is essential to the output.

### Locke's Labor Theory Of Ownership

One way we can begin to make sense of the morality on claiming AI generated content is through applying John Locke's views on property. To Locke, property rights come from mixing your labor with resources. So for instance, people couldn't just walk into unclaimed land and pronounce their ownership of it.
Instead, they needed to meaningfully transform it through their work. Building a house turns trees and stones into **your** shelter. Growing crops transforms unused soil into **your** food. These labor-intensive activities create most of the value, and that's what gives you a legitimate claim to ownership.

### Making Claims On AI Generated Content

AI systems, like ChatGPT, make some forms of intelligence a common resource. Prior to its invention, the only way to get a letter was to use your own intelligence a resource you already own. You could of course steal a letter by plagarising, but plagarism is obviously immoral because it involves someone else's property.
With intelligence now becoming a common resource we will have to apply Locke's Theory Of Ownership to assess the morality of people's property claims. We will need a framework which can help us piece together how to make sense of this new world.

### A Framework for Evaluating AI Content Claims

With Locke's labory theory as a foundation, we can begin a first pass on a framework to evaluate the legitimacy of the ownership on AI-generated content. The framework considers three factors: creative input, transformative effort, and transparency.

1. Creative Input:
   Consider the person who uses an AI tool to assist them in writing a screenplay. A key part is that the human contributes a creative idea for the content. The creative input should be a significant and unique contribution in which the rest of the content would not exist without.
