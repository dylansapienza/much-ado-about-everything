<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Much Ado About Everything</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Much Ado About Everything</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Dec 2024 10:34:30 -0500</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Are We Outsourcing Reasoning to AI?</title>
      <link>http://localhost:1313/posts/outsourcing-reasoning-to-ai/</link>
      <pubDate>Thu, 26 Dec 2024 10:34:30 -0500</pubDate>
      <guid>http://localhost:1313/posts/outsourcing-reasoning-to-ai/</guid>
      <description>This article has been updated as of December 26th. It was originally published on November 23rd, 2023.
1. Outsourcing Human Capabilities In Nicholas Carr’s book, The Shallows, he advances the idea that modern technologies like the internet, hard drives, and other software innovations can negatively impact natural human abilities. To motivate this view to those who haven’t read his book I will sketch out a general form of his argument. Then I will show a particular cases as examples to help align our intuitions.</description>
    </item>
    <item>
      <title>Some thoughts on AI Doomerism: Digital Labor</title>
      <link>http://localhost:1313/posts/digitallabor/</link>
      <pubDate>Mon, 23 Dec 2024 16:55:13 -0500</pubDate>
      <guid>http://localhost:1313/posts/digitallabor/</guid>
      <description>Most Americans are concerned about Artifical Intelligence. They often cite labor replacement, cyber security, geopolitical risks, information integrity, privacy and creepiness as reasons for their concern. People who are extremely concerned with the impacts of AI on our society are AI Doomers. Doomerism in AI can come in many forms, but for this piece I want to discuss one of the most frequently cited scenarios: Labor Replacement.
The State of Discourse on Labor Replacement Labor replacement is a way of formalizing the concern that AI systems will take current human jobs.</description>
    </item>
    <item>
      <title>Who Is Reinforcing Who?: Recommendation Algorithms</title>
      <link>http://localhost:1313/posts/dualeffect-recommendations/dualeffect-recommendations/</link>
      <pubDate>Mon, 16 Sep 2024 19:33:58 -0400</pubDate>
      <guid>http://localhost:1313/posts/dualeffect-recommendations/dualeffect-recommendations/</guid>
      <description>Recommendation Algorithms determine what content we see next on many social media platforms. These algorithms have risen to take the place of the previous method, where posts were sorted by newest to oldest. Algorithmic sorting prevades nearly all our social media apps. Instagram, TikTok, Youtube, X, and even LinkedIn, have all transistioned over to this new &amp;ldquo;For You&amp;rdquo; type experience. Not by mistake, social media companies adopt recommendation algorithms because of how effective they are at keeping users on app.</description>
    </item>
    <item>
      <title>What Is Going On With Short Form Video?</title>
      <link>http://localhost:1313/posts/shortformvideo/shortformvideo/</link>
      <pubDate>Mon, 05 Aug 2024 18:08:09 -0400</pubDate>
      <guid>http://localhost:1313/posts/shortformvideo/shortformvideo/</guid>
      <description>Entertainment is expressed through many different mediums. One of the mediums that I want to focus on today is algorithmically recommended short form video. I will break down this medium so we have a sturdy definition before continuing. Starting with short form video, I will define this as content which is less than 5 minutes in length. Although the upperbound is set at 5 minutes, typical clips may be as short as 5 seconds.</description>
    </item>
    <item>
      <title>You Know It When You See It: Knowing Without Knowing</title>
      <link>http://localhost:1313/posts/youknowitwhenyouseeit/youknowitwhenyouseeit/</link>
      <pubDate>Wed, 24 Jul 2024 21:48:13 -0400</pubDate>
      <guid>http://localhost:1313/posts/youknowitwhenyouseeit/youknowitwhenyouseeit/</guid>
      <description>An Example (Recall): You are at a bar with some friends. You are talking about movies and you&amp;rsquo;re trying to remember that one movie from the 1960s about a court case. You feel like you really know it, but you just can&amp;rsquo;t find it in your head. You are also struggling to recall characters and other ways to signal to others what movie you are seaching for. You snap your fingers, look up the the ceiling, let out some &amp;ldquo;umms and ahhs&amp;rdquo; as you feel yourself getting frustrated.</description>
    </item>
    <item>
      <title>Large Language Models and The Utility of Personas</title>
      <link>http://localhost:1313/posts/llm-personas/llm-personas/</link>
      <pubDate>Tue, 23 Apr 2024 17:35:49 -0400</pubDate>
      <guid>http://localhost:1313/posts/llm-personas/llm-personas/</guid>
      <description>Some Background Large Language Models like ChatGPT, Claude and Google Bard share a common persona, that of an AI Assistant. They all act as friendly, helpful, sensitive, human aligned chatbots.
Let&amp;rsquo;s prompt two AI chat applications to ask who they are. You&amp;rsquo;ll see we get surprisingly similar responses.
ChatGPT 3.5&amp;rsquo;s purpose is to assist with a wide range of tasks
Anthropic Claude is an assistant that is helpful harmless and honest</description>
    </item>
    <item>
      <title>The Correctness Trap: How Overreliance on Systems Can Mislead From Truth</title>
      <link>http://localhost:1313/posts/correctness-truth/</link>
      <pubDate>Mon, 01 Apr 2024 17:35:49 -0400</pubDate>
      <guid>http://localhost:1313/posts/correctness-truth/</guid>
      <description>Correct vs. True? What is the difference between something correct and something true? Is correctness the same as truthfulness? In other words, are all instances of correctness identical with truthfulness?
Correctness-Truth Alignment
For a Proposition P, where P is correct, P must also be true
At first glance, it seems like they must be. For example, consider a math test. On the test, if you solve an equation, you will be marked as correct.</description>
    </item>
    <item>
      <title>Patterns &amp; Theories</title>
      <link>http://localhost:1313/posts/my-first-post/</link>
      <pubDate>Fri, 23 Feb 2024 16:03:05 -0500</pubDate>
      <guid>http://localhost:1313/posts/my-first-post/</guid>
      <description>The world is made of events and like any assortment of data points there can be patterns found. With these patterns we tend to find the story which underlies them, which makes sense of them. These patterns often help us predict the future, solve problems, and are sometimes just pleasing see. What can a deep dive on the concept of patterns reveal about their nature?
1. What is the form of a pattern?</description>
    </item>
  </channel>
</rss>
